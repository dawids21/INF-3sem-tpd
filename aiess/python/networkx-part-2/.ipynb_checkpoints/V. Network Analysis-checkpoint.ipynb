{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Graph Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll cover some common network analysis techniques. This doesn't cover everything NetworkX is capable of, but is a should get you started exploring the rest of the package.\n",
    "\n",
    "First we are going to need import some other packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:54:42.610265Z",
     "start_time": "2019-04-11T19:54:42.605852Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little jupyter magic ([literally](https://ipython.org/ipython-doc/3/interactive/tutorial.html#magics-explained)], to make sure plots show up in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:54:43.299691Z",
     "start_time": "2019-04-11T19:54:43.292909Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common feature of complex networks it's their degree distribution. This is often represented as degree rank plot. Let's check out the degree rank plot of a BA Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:54:44.171106Z",
     "start_time": "2019-04-11T19:54:44.094195Z"
    }
   },
   "outputs": [],
   "source": [
    "BA = nx.barabasi_albert_graph(10000,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the correct degree sequence, we need to get the degrees sorted in descending order. Most NetworkX functions return a dictionary, with the keys being the nodes (or edges) and the values being the result of whatever measure you are running. So we want to sort the values in reverse order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:54:53.111670Z",
     "start_time": "2019-04-11T19:54:53.072857Z"
    }
   },
   "outputs": [],
   "source": [
    "degrees = dict(BA.degree())\n",
    "degree_sequence = sorted(degrees.values(),reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to do some plotting. Plotting using matplotlib is a lot like plotting using MATLAB. Because the degree distribution of a BA graph is a power-law, we'd like to use a plot with log scales. Here is how we'd do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T19:54:55.478498Z",
     "start_time": "2019-04-11T19:54:54.919696Z"
    }
   },
   "outputs": [],
   "source": [
    "# loglog tells matplotlib to use log scales.\n",
    "# The x values, range(1,10001), are the ranks, \n",
    "# and the degree_sequence are the y values.\n",
    "# The String 'k.' means use black (k) dots (.)\n",
    "plt.loglog(range(1,BA.order()+1),degree_sequence,'k.')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Degree')\n",
    "plt.ylim(1,max(degree_sequence)+1)\n",
    "plt.xlim(.9,10001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib is a powerful tool more info can be found on using it [here](http://matplotlib.org/users/beginner.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree Distribution of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the original paper where the Barabási–Albert model was introduced it was stated that it provided a good explanation for the Autonomous Sytems Network. Let's build a network with similar degree structure to a recent snapshot of the Autonomous Systems Network. The data was retrieved from [UCLA's Internet Research Lab's Topology Data](http://irl.cs.ucla.edu/topology/).\n",
    "\n",
    "First, read in the network, it is in the data folder labeled `20150201.link.v4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:01:56.782442Z",
     "start_time": "2019-04-11T20:01:55.898103Z"
    }
   },
   "outputs": [],
   "source": [
    "AS = nx.read_edgelist('data/20150201.link.v4', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out the number of nodes and edges in the networks, and the average degree of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:02:00.450360Z",
     "start_time": "2019-04-11T20:02:00.373991Z"
    }
   },
   "outputs": [],
   "source": [
    "AS.order(),AS.size(),(2.0*AS.size())/AS.order()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use these values as approximates to create a BA graph of the same size with almost the same number of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:02:26.110800Z",
     "start_time": "2019-04-11T20:02:26.101710Z"
    }
   },
   "outputs": [],
   "source": [
    "BA = nx.barabasi_albert_graph(#Fill in the rest AS.order(),8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the degree sequence of each, and use the code below to plot each. Is this a good model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BA_deg_seq = #\n",
    "AS_deg_seq = #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(BA_deg_seq,'b.',label='BA Model')\n",
    "plt.loglog(AS_deg_seq,'r.',label='AS Data')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Degree')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A note on power laws. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is oftern claimed that networks have power-law degree distribution. That is the probability of degree k is proportional to \n",
    "\n",
    "$$Pr[k] \\sim \\frac{1}{k^\\alpha}$$\n",
    "\n",
    "Where, $\\alpha$ is some constant. Often this is claimed pased on linear regressions of degree/rank plots. However, the appropriate way to fit power-laws is using maximum likelihood techniques. See [1] for more info\n",
    "\n",
    "[1] Clauset, Aaron, Cosma Rohilla Shalizi, and Mark EJ Newman. \"Power-law distributions in empirical data.\" _SIAM review_ 51.4 (2009): 661-703."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying important nodes is often a common technique in complex network analysis. Degree is a simple measure of centrality, but there are many others. Let's explore a few on some real data on Terrorists in Colonial America. I wish I could claim I came up with this, but I didn't all credit goes to \n",
    "\n",
    "[1] http://kieranhealy.org/blog/archives/2013/06/09/using-metadata-to-find-paul-revere/\n",
    "\n",
    "[2] Fischer, David Hackett. Historians' fallacies: Toward a logic of historical thought. Vol. 1970. London: Routledge & Kegan Paul, 1971.\n",
    "\n",
    "The data file contains a graph with two types of nodes, 'Organization' and 'Person'. Organizations are different groups who met in colonial America and supported independence from England. People are people attending those meetings. \n",
    "\n",
    "First let's get the data from `data/PaulRevereAppD.csv` file, then transform it to extract nodes representing people and organizations, and read it into NetworkX. Check the docs on [how to read bipartite graphs in NetworkX](https://networkx.github.io/documentation/stable/reference/algorithms/bipartite.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:40:43.844030Z",
     "start_time": "2019-04-11T20:40:43.831970Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/PaulRevereAppD.csv', index_col='Person')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:41:56.555434Z",
     "start_time": "2019-04-11T20:41:56.522011Z"
    }
   },
   "outputs": [],
   "source": [
    "tups = [\n",
    "    (person, organization, membership) \n",
    "    for (person, organization, membership) \n",
    "    in df.stack().reset_index().values.tolist()\n",
    "    if membership == 1\n",
    "]\n",
    "tups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:10:40.393253Z",
     "start_time": "2019-04-11T20:10:40.389955Z"
    }
   },
   "outputs": [],
   "source": [
    "G = nx.read_somehow_this_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Check out the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:11:21.023518Z",
     "start_time": "2019-04-11T20:11:21.005416Z"
    }
   },
   "outputs": [],
   "source": [
    "G.edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the edges are between people and organizations. We are curious about the connections between people. We could write a function to create a new graph in which two people are connected if they co-attend a meeting, and the edge has a weight indicates the number of meetings they both attended. But that sounds hard, luckily NetworkX can do it for us. First let's make a list of nodes for organizations and people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgs = [n for n in G.nodes() if G.node[n]['type']=='Organization']\n",
    "people = [n for n in G.nodes() if G.node[n]['type']=='Person']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use that handy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = nx.bipartite.weighted_projected_graph(G,orgs) # Connections between people based on co-meeting attendence\n",
    "R = nx.bipartite.weighted_projected_graph(G,people) # Overlap among meeting attendees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a quick python trick to determine who has the highest degree. Adding the keyword wight indicates that we should use _weighted_ edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = R.degree(weight='weight')\n",
    "sorted(deg.items(), # Look at all the degrees as a tuple (node,degree)\n",
    "       key=lambda i: i[1], # Sort the list by the second item in the tuple\n",
    "       reverse=True)[:5] # Reverse the list (highest degree first), and only give the first 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important measure of centrality is the betweenneess centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btw = nx.betweenness_centrality(R,weight='weight')\n",
    "sorted(btw.items(),\n",
    "       key=lambda i: i[1],\n",
    "       reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try plotting the betweenness centrality vs the degree for each node. Instead of using `plt.loglog`, use `plt.semilogy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a similar analysis with the network of oranizations `O`, which is organziation is most central to the revolution?\n",
    "\n",
    "First calculate the degree and betweenness for each of the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = O.degree()\n",
    "btw = nx.betweenness_centrality(O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of organizations is small, it might not be the worst idea to draw the network. Here is a Red, White and Blue network drawing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = [G.degree(org)**2 for org in O.nodes()]\n",
    "width = [d['weight'] for (u,v,d) in O.edges(data=True)]\n",
    "\n",
    "plt.figure(figsize=(14,10)) #We'll make it bigger\n",
    "nx.draw(M, width=width,\n",
    "           with_labels=True,\n",
    "           edge_color='r',\n",
    "           node_color='b',\n",
    "           node_size=size,\n",
    "           font_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase Transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some random graph models experience phase transitions like other physical phenomona. For example, the Erdos-Renyi graph that we already explored experiences a phase transition in the size of the giant connected component when the average degree of the model cross a certain threshold. We are going to use NetworkX to explore that threshold. \n",
    "\n",
    "Recall that an Erdos-Renyi random graph is one where there is an edge between each node with probability $p$. The ER model has expected number of Edges $\\mathbb{E}[|E|]={n \\choose 2}p$. With a little math on the degree distribution, we can find that the average degree will be $k=np$, and $p=\\frac{k}{n}$.\n",
    "\n",
    "The giant component is defined as the largest connected component in the graph. Let's explore how the size of the giant component changes for a graph of size 100, as we incrase the average degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:21:18.288768Z",
     "start_time": "2019-04-11T20:21:17.759781Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "ks = np.arange(.1,3,.02)\n",
    "GCC_size = []\n",
    "for k in ks:\n",
    "    G = nx.gnp_random_graph(n,k/n)\n",
    "    GC = sorted(nx.connected_component_subgraphs(G),key=lambda C: len(C),reverse=True)[0]\n",
    "    GCC_size.append(float(len(GC))/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:21:19.384685Z",
     "start_time": "2019-04-11T20:21:19.162384Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(ks,GCC_size,marker='.',lw=0)\n",
    "plt.xlabel('Average Degree')\n",
    "plt.ylabel('Relative size of Giant Component')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty messy. This is because each graph is a random instance. Let's make 50 graphs for each possible average degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:21:32.394741Z",
     "start_time": "2019-04-11T20:21:27.043321Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 50 # Number of times to create a graph\n",
    "n = 100 # Graph Size\n",
    "ks = np.arange(.1,3,.1) # A bunch of average degrees, separated by .1 from .1 to 3\n",
    "GCC_size = [] #List to store the size of the giant component\n",
    "for k in ks:\n",
    "    GCs = []\n",
    "    for _ in range(N):\n",
    "        G = nx.gnp_random_graph(n,k/n) #generate teh graph\n",
    "        GC = sorted(nx.connected_component_subgraphs(G),key=lambda C: len(C),reverse=True)[0] #graph teh largest component\n",
    "        GCs.append(float(len(GC))/n) # Measure it's size\n",
    "    GCC_size.append(np.mean(GCs)) # Take the average and append it to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:21:33.359346Z",
     "start_time": "2019-04-11T20:21:33.191899Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(ks,GCC_size,marker='.',lw=0)\n",
    "plt.xlabel('Average Degree')\n",
    "plt.ylabel('Average Relative size of Giant Component')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test it for various values of $n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:23:08.451415Z",
     "start_time": "2019-04-11T20:21:39.193687Z"
    }
   },
   "outputs": [],
   "source": [
    "ks = np.arange(.1,3,.1)\n",
    "N = 50\n",
    "for n in [10,50,100,250,500]:\n",
    "    print(n)\n",
    "    GCC_size = []\n",
    "    for k in ks:\n",
    "        GCs = []\n",
    "        for _ in range(N):\n",
    "            G = nx.gnp_random_graph(n,k/n)\n",
    "            GC = sorted(nx.connected_component_subgraphs(G),key=lambda C: len(C),reverse=True)[0]\n",
    "            GCs.append(float(len(GC))/n)\n",
    "        GCC_size.append(np.mean(GCs))\n",
    "    plt.plot(ks,GCC_size,marker='.',label=str(n),lw=0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Average Degree')\n",
    "plt.ylabel('Relative size of Giant Component')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the transition gets sharper as $n$ gets larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Determining different node types solely from network data is one of the most powerful tools in network analysis. NetworkX has limited capacity for community detection, but some new algorithms are coming with version 2.0. I've included one function here in the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:24:11.825762Z",
     "start_time": "2019-04-11T20:24:11.820634Z"
    }
   },
   "outputs": [],
   "source": [
    "import community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first is a classic algorithm due to Girvan-Newman. It progressively removes the highest betweenness edges from a graph until graph becomes disconnected. Then it repeateds the process into successively smaller groups. Let's test it on a generated graph we know has two communities.\n",
    "\n",
    "A connected caveman graph is a graph with $k$ complete graphs connected in a ring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:24:13.462184Z",
     "start_time": "2019-04-11T20:24:13.458472Z"
    }
   },
   "outputs": [],
   "source": [
    "G = nx.connected_caveman_graph(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:24:14.674736Z",
     "start_time": "2019-04-11T20:24:14.666770Z"
    }
   },
   "outputs": [],
   "source": [
    "group1 = range(10)\n",
    "group2 = range(10,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what partitions Girvan Newman can partition the graph correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:24:17.895093Z",
     "start_time": "2019-04-11T20:24:17.867351Z"
    }
   },
   "outputs": [],
   "source": [
    "comm = community.girvan_newman(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`comm` will have the breakdown of the graph at each stage of the algorithm, so the first item in the list is the graph broken into two parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:24:19.792338Z",
     "start_time": "2019-04-11T20:24:19.787377Z"
    }
   },
   "outputs": [],
   "source": [
    "comm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:28:12.785893Z",
     "start_time": "2019-04-11T20:28:12.641289Z"
    }
   },
   "outputs": [],
   "source": [
    "nc = lambda lst: [x in comm[0][0] for x in lst]\n",
    "\n",
    "nx.draw(G, node_color=nc(G.nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you try with the karate club graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:28:14.965762Z",
     "start_time": "2019-04-11T20:28:14.958046Z"
    }
   },
   "outputs": [],
   "source": [
    "KC = nx.karate_club_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:28:15.680563Z",
     "start_time": "2019-04-11T20:28:15.545804Z"
    }
   },
   "outputs": [],
   "source": [
    "comm = community.girvan_newman(KC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the algorithm did on identifying different groups. In the Karate Club Graph, nodes have an attribute `club` which is the group affiliatino and is either `Mr. Hi` or `Officer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:28:17.320140Z",
     "start_time": "2019-04-11T20:28:17.315499Z"
    }
   },
   "outputs": [],
   "source": [
    "KC.nodes(data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two lists, one with all the nodes who are members of Mr. Hi's group and those that are members of Officer's group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrHi = #\n",
    "officer = #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare them to the divisions found by the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(comm[0][0]),sorted(mrHi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(comm[0][1]),sorted(officer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this graph isn't that large, we could actually plot it. We'll make the first found community red, and the second community blue. If the nodes are misclassified we'll put a thick border around them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = []\n",
    "for n in KC.nodes():\n",
    "    if n in comm[0][0]:\n",
    "        colors.append('r')\n",
    "    else:\n",
    "        colors.append('b')\n",
    "lwidths = []\n",
    "for n in KC.nodes():\n",
    "    if n in comm[0][0] and n in mrHi:\n",
    "        lwidths.append(0.5)\n",
    "    elif n in comm[0][1] and n in officer:\n",
    "        lwidths.append(0.5)\n",
    "    else:\n",
    "        lwidths.append(2)\n",
    "nx.draw(KC,node_color=colors,linewidths=lwidths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
